vllm:
  dtype: bfloat16
  tensor_parallel_size: 4
  pipeline_parallel_size: 1
  distributed_executor_backend: mp
  max_num_seqs: 256
  max_model_len: 16384
  max_num_batched_tokens: 16384
  max_seq_len_to_capture: 8192
  gpu_memory_utilization: 0.95
  block_size: 128
  swap_space: 16
  cpu_offload_gb: 0
  scheduling_policy: priority
  num_scheduler_steps: 1
  disable_async_output_proc: true
  multi_step_stream_outputs: true
  enable_chunked_prefill: true
  enable_prefix_caching: true
  enforce_eager: true
  quantization: compressed-tensors
engine_type: vllm
model: MindSDK/DeepSeek-R1-Distill-Llama-70B-quantized.w8a8
