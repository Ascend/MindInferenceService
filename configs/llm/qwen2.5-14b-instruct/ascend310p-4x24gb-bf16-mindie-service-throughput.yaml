mindie-service:
  tensor_parallel_size: 4
  pipeline_parallel_size: 1
  distributed_executor_backend: mp
  max_num_seqs: 64
  max_model_len: 65536
  max_num_batched_tokens: 65536
  max_seq_len_to_capture: 65536
  gpu_memory_utilization: 0.95
  block_size: 128
  swap_space: 16
  scheduling_policy: fcfs
  vllm_allow_long_max_model_len: true
engine_type: mindie-service
model: MindSDK/Qwen2.5-14B-Instruct
