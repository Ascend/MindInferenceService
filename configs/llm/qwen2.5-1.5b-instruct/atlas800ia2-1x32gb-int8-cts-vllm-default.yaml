vllm:
  dtype: bfloat16
  tensor_parallel_size: 1
  pipeline_parallel_size: 1
  max_num_seqs: 128
  gpu_memory_utilization: 0.9
  block_size: 32
  swap_space: 0
  cpu_offload_gb: 0
  scheduling_policy: fcfs
  enforce_eager: true
  quantization: compressed-tensors
engine_type: vllm
model: MindSDK/Qwen2.5-1.5B-Instruct-quantized.w8a8
