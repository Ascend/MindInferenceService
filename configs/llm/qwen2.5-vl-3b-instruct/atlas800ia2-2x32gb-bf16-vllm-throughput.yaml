vllm:
  dtype: bfloat16
  tensor_parallel_size: 2
  pipeline_parallel_size: 1
  max_num_seqs: 64
  max_model_len: 42000
  max_num_batched_tokens: 42000
  max_seq_len_to_capture: 42000
  gpu_memory_utilization: 0.85
  block_size: 128
  swap_space: 8
  cpu_offload_gb: 0
  scheduling_policy: fcfs
  disable_async_output_proc: false
  multi_step_stream_outputs: true
  enable_chunked_prefill: false
  enable_prefix_caching: false
  enforce_eager: true
engine_type: vllm
model: MindSDK/Qwen2.5-VL-3B-Instruct
model_type: VLM
