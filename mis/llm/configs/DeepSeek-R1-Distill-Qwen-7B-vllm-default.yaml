dtype: ""bfloat16"

tensor_parallel_size: 1
pipline_parallel_size: 1

max_num_seqs: 512
max_model_len: 8192
max_num_batched_tokens: 8192
max_seq_len_to_capture: 8192

gpu_memory_utilization: 0.9
block_size: 64
swap_space: 0
cpu_offload_gb: 0

scheduling_policy: "fcfs"

enforce_eager: true
